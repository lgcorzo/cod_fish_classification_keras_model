{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"frcnn_train_vgg.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558099456304,"user_tz":-120,"elapsed":21996,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"kauOILHSqXWw","outputId":"1fe9a6f8-8c54-47fd-a892-e0106fb759df","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558099460650,"user_tz":-120,"elapsed":2981,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"_fzxugFjqc2T","outputId":"6e3539c5-e4bb-47eb-8cce-7a4b74831da1","colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["!ls\n","%cd './drive/My Drive/trabajo_finmaster_peces'\n","!ls"],"execution_count":2,"outputs":[{"output_type":"stream","text":["drive  sample_data\n","/content/drive/My Drive/trabajo_finmaster_peces\n","annotation.txt\t\t\t\t\t test\n","frcnn_test_vgg.ipynb\t\t\t\t test_annotation.txt\n","frcnn_train_vgg.ipynb\t\t\t\t test.csv\n","model\t\t\t\t\t\t train\n","model_vgg_config.pickle\t\t\t\t train.csv\n","Object_Detection_DataPreprocessing_granit.ipynb  Trained\n","README.md\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UauKNtFRqydu"},"source":["### Import libs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qSbY3Amlqpkh","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"200eae90-375d-4811-97fc-2bc8269a24b3","executionInfo":{"status":"ok","timestamp":1558099464589,"user_tz":-120,"elapsed":2219,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}}},"source":["from __future__ import division\n","from __future__ import print_function\n","from __future__ import absolute_import\n","import random\n","import pprint\n","import sys\n","import time\n","import numpy as np\n","from optparse import OptionParser\n","import pickle\n","import math\n","import cv2\n","import copy\n","from matplotlib import pyplot as plt\n","import tensorflow as tf\n","import pandas as pd\n","import os\n","\n","from sklearn.metrics import average_precision_score\n","\n","from keras import backend as K\n","from keras.optimizers import Adam, SGD, RMSprop\n","from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n","from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n","from keras.engine.topology import get_source_inputs\n","from keras.utils import layer_utils\n","from keras.utils.data_utils import get_file\n","from keras.objectives import categorical_crossentropy\n","\n","from keras.models import Model\n","from keras.utils import generic_utils\n","from keras.engine import Layer, InputSpec\n","from keras import initializers, regularizers"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WrH5i5mmrDWY"},"source":["#### Config setting"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DvJm0FFRsyVu","colab":{}},"source":["class Config:\n","\n","\tdef __init__(self):\n","\n","\t\t# Print the process or not\n","\t\tself.verbose = True\n","\n","\t\t# Name of base network\n","\t\tself.network = 'vgg'\n","\n","\t\t# Setting for data augmentation\n","\t\tself.use_horizontal_flips = False\n","\t\tself.use_vertical_flips = False\n","\t\tself.rot_90 = False\n","\n","\t\t# Anchor box scales\n","    # Note that if im_size is smaller, anchor_box_scales should be scaled\n","    # Original anchor_box_scales in the paper is [128, 256, 512]\n","\t\tself.anchor_box_scales = [64, 128, 256] \n","\n","\t\t# Anchor box ratios\n","\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n","\n","\t\t# Size to resize the smallest side of the image\n","\t\t# Original setting in paper is 600. Set to 300 in here to save training time\n","\t\tself.im_size = 300\n","\n","\t\t# image channel-wise mean to subtract\n","\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n","\t\tself.img_scaling_factor = 1.0\n","\n","\t\t# number of ROIs at once\n","\t\tself.num_rois = 4\n","\n","\t\t# stride at the RPN (this depends on the network configuration)\n","\t\tself.rpn_stride = 16\n","\n","\t\tself.balanced_classes = False\n","\n","\t\t# scaling the stdev\n","\t\tself.std_scaling = 4.0\n","\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n","\n","\t\t# overlaps for RPN\n","\t\tself.rpn_min_overlap = 0.3\n","\t\tself.rpn_max_overlap = 0.7\n","\n","\t\t# overlaps for classifier ROIs\n","\t\tself.classifier_min_overlap = 0.1\n","\t\tself.classifier_max_overlap = 0.5\n","\n","\t\t# placeholder for the class mapping, automatically generated by the parser\n","\t\tself.class_mapping = None\n","\n","\t\tself.model_path = None"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"o0bIjlycyR9_"},"source":["#### Parser the data from annotation file"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vc89E9uAydTX","colab":{}},"source":["def get_data(input_path):\n","\t\"\"\"Parse the data from annotation file\n","\t\n","\tArgs:\n","\t\tinput_path: annotation file path\n","\n","\tReturns:\n","\t\tall_data: list(filepath, width, height, list(bboxes))\n","\t\tclasses_count: dict{key:class_name, value:count_num} \n","\t\t\te.g. {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745}\n","\t\tclass_mapping: dict{key:class_name, value: idx}\n","\t\t\te.g. {'Car': 0, 'Mobile phone': 1, 'Person': 2}\n","\t\"\"\"\n","\tfound_bg = False\n","\tall_imgs = {}\n","\n","\tclasses_count = {}\n","\n","\tclass_mapping = {}\n","\n","\tvisualise = True\n","\n","\ti = 1\n","\t\n","\twith open(input_path,'r') as f:\n","\n","\t\tprint('Parsing annotation files')\n","\n","\t\tfor line in f:\n","\n","\t\t\t# Print process\n","\t\t\tsys.stdout.write('\\r'+'idx=' + str(i))\n","\t\t\ti += 1\n","\n","\t\t\tline_split = line.strip().split(',')\n","\n","\t\t\t# Make sure the info saved in annotation file matching the format (path_filename, x1, y1, x2, y2, class_name)\n","\t\t\t# Note:\n","\t\t\t#\tOne path_filename might has several classes (class_name)\n","\t\t\t#\tx1, y1, x2, y2 are the pixel value of the origial image, not the ratio value\n","\t\t\t#\t(x1, y1) top left coordinates; (x2, y2) bottom right coordinates\n","\t\t\t#   x1,y1-------------------\n","\t\t\t#\t|\t\t\t\t\t\t|\n","\t\t\t#\t|\t\t\t\t\t\t|\n","\t\t\t#\t|\t\t\t\t\t\t|\n","\t\t\t#\t|\t\t\t\t\t\t|\n","\t\t\t#\t---------------------x2,y2\n","\n","\t\t\t(filename,x1,y1,x2,y2,class_name) = line_split\n","\n","\t\t\tif class_name not in classes_count:\n","\t\t\t\tclasses_count[class_name] = 1\n","\t\t\telse:\n","\t\t\t\tclasses_count[class_name] += 1\n","\n","\t\t\tif class_name not in class_mapping:\n","\t\t\t\tif class_name == 'bg' and found_bg == False:\n","\t\t\t\t\tprint('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n","\t\t\t\t\tfound_bg = True\n","\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n","\n","\t\t\tif filename not in all_imgs:\n","\t\t\t\tall_imgs[filename] = {}\n","\t\t\t\t\n","\t\t\t\timg = cv2.imread(filename)\n","\t\t\t\t(rows,cols) = img.shape[:2]\n","\t\t\t\tall_imgs[filename]['filepath'] = filename\n","\t\t\t\tall_imgs[filename]['width'] = cols\n","\t\t\t\tall_imgs[filename]['height'] = rows\n","\t\t\t\tall_imgs[filename]['bboxes'] = []\n","\t\t\t\t# if np.random.randint(0,6) > 0:\n","\t\t\t\t# \tall_imgs[filename]['imageset'] = 'trainval'\n","\t\t\t\t# else:\n","\t\t\t\t# \tall_imgs[filename]['imageset'] = 'test'\n","\n","\t\t\tall_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n","\n","\n","\t\tall_data = []\n","\t\tfor key in all_imgs:\n","\t\t\tall_data.append(all_imgs[key])\n","\t\t\n","\t\t# make sure the bg class is last in the list\n","\t\tif found_bg:\n","\t\t\tif class_mapping['bg'] != len(class_mapping) - 1:\n","\t\t\t\tkey_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n","\t\t\t\tval_to_switch = class_mapping['bg']\n","\t\t\t\tclass_mapping['bg'] = len(class_mapping) - 1\n","\t\t\t\tclass_mapping[key_to_switch] = val_to_switch\n","\t\t\n","\t\treturn all_data, classes_count, class_mapping"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oFvqGs4acGWl"},"source":["#### Define ROI Pooling Convolutional Layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"6l32Q85kcMpB","colab":{}},"source":["class RoiPoolingConv(Layer):\n","    '''ROI pooling layer for 2D inputs.\n","    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n","    K. He, X. Zhang, S. Ren, J. Sun\n","    # Arguments\n","        pool_size: int\n","            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n","        num_rois: number of regions of interest to be used\n","    # Input shape\n","        list of two 4D tensors [X_img,X_roi] with shape:\n","        X_img:\n","        `(1, rows, cols, channels)`\n","        X_roi:\n","        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n","    # Output shape\n","        3D tensor with shape:\n","        `(1, num_rois, channels, pool_size, pool_size)`\n","    '''\n","    def __init__(self, pool_size, num_rois, **kwargs):\n","\n","        self.dim_ordering = K.image_dim_ordering()\n","        self.pool_size = pool_size\n","        self.num_rois = num_rois\n","\n","        super(RoiPoolingConv, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        self.nb_channels = input_shape[0][3]   \n","\n","    def compute_output_shape(self, input_shape):\n","        return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n","\n","    def call(self, x, mask=None):\n","\n","        assert(len(x) == 2)\n","\n","        # x[0] is image with shape (rows, cols, channels)\n","        img = x[0]\n","\n","        # x[1] is roi with shape (num_rois,4) with ordering (x,y,w,h)\n","        rois = x[1]\n","\n","        input_shape = K.shape(img)\n","\n","        outputs = []\n","\n","        for roi_idx in range(self.num_rois):\n","\n","            x = rois[0, roi_idx, 0]\n","            y = rois[0, roi_idx, 1]\n","            w = rois[0, roi_idx, 2]\n","            h = rois[0, roi_idx, 3]\n","\n","            x = K.cast(x, 'int32')\n","            y = K.cast(y, 'int32')\n","            w = K.cast(w, 'int32')\n","            h = K.cast(h, 'int32')\n","\n","            # Resized roi of the image to pooling size (7x7)\n","            rs = tf.image.resize_images(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n","            outputs.append(rs)\n","                \n","\n","        final_output = K.concatenate(outputs, axis=0)\n","\n","        # Reshape to (1, num_rois, pool_size, pool_size, nb_channels)\n","        # Might be (1, 4, 7, 7, 3)\n","        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n","\n","        # permute_dimensions is similar to transpose\n","        final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n","\n","        return final_output\n","    \n","    \n","    def get_config(self):\n","        config = {'pool_size': self.pool_size,\n","                  'num_rois': self.num_rois}\n","        base_config = super(RoiPoolingConv, self).get_config()\n","        return dict(list(base_config.items()) + list(config.items()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Mf2taA29RFNs"},"source":["#### Vgg-16 model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WaBQfl4XRJY3","colab":{}},"source":["def get_img_output_length(width, height):\n","    def get_output_length(input_length):\n","        return input_length//16\n","\n","    return get_output_length(width), get_output_length(height)    \n","\n","def nn_base(input_tensor=None, trainable=False):\n","\n","\n","    input_shape = (None, None, 3)\n","\n","    if input_tensor is None:\n","        img_input = Input(shape=input_shape)\n","    else:\n","        if not K.is_keras_tensor(input_tensor):\n","            img_input = Input(tensor=input_tensor, shape=input_shape)\n","        else:\n","            img_input = input_tensor\n","\n","    bn_axis = 3\n","\n","    # Block 1\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n","    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n","\n","    # Block 2\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n","    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n","\n","    # Block 3\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n","    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n","\n","    # Block 4\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n","    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n","\n","    # Block 5\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n","    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n","    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"xcOi5MIMVJpU"},"source":["####  RPN layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gsuV21vpRczQ","colab":{}},"source":["def rpn_layer(base_layers, num_anchors):\n","    \"\"\"Create a rpn layer\n","        Step1: Pass through the feature map from base layer to a 3x3 512 channels convolutional layer\n","                Keep the padding 'same' to preserve the feature map's size\n","        Step2: Pass the step1 to two (1,1) convolutional layer to replace the fully connected layer\n","                classification layer: num_anchors (9 in here) channels for 0, 1 sigmoid activation output\n","                regression layer: num_anchors*4 (36 in here) channels for computing the regression of bboxes with linear activation\n","    Args:\n","        base_layers: vgg in here\n","        num_anchors: 9 in here\n","\n","    Returns:\n","        [x_class, x_regr, base_layers]\n","        x_class: classification for whether it's an object\n","        x_regr: bboxes regression\n","        base_layers: vgg in here\n","    \"\"\"\n","    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n","\n","    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n","    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n","\n","    return [x_class, x_regr, base_layers]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0fBt9xNFWsKS"},"source":["####  Classifier layer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0PKSPLRLWwMz","colab":{}},"source":["def classifier_layer(base_layers, input_rois, num_rois, nb_classes = 4):\n","    \"\"\"Create a classifier layer\n","    \n","    Args:\n","        base_layers: vgg\n","        input_rois: `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n","        num_rois: number of rois to be processed in one time (4 in here)\n","\n","    Returns:\n","        list(out_class, out_regr)\n","        out_class: classifier layer output\n","        out_regr: regression layer output\n","    \"\"\"\n","\n","    input_shape = (num_rois,7,7,512)\n","\n","    pooling_regions = 7\n","\n","    # out_roi_pool.shape = (1, num_rois, channels, pool_size, pool_size)\n","    # num_rois (4) 7x7 roi pooling\n","    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n","\n","    # Flatten the convlutional layer and connected to 2 FC and 2 dropout\n","    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n","    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n","    out = TimeDistributed(Dropout(0.5))(out)\n","    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n","    out = TimeDistributed(Dropout(0.5))(out)\n","\n","    # There are two output layer\n","    # out_class: softmax acivation function for classify the class name of the object\n","    # out_regr: linear activation function for bboxes coordinates regression\n","    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n","    # note: no regression target for bg class\n","    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n","\n","    return [out_class, out_regr]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WMev3UMadCzJ"},"source":["#### Calculate IoU (Intersection of Union)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Jy5iIBYgdCJD","colab":{}},"source":["def union(au, bu, area_intersection):\n","\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n","\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n","\tarea_union = area_a + area_b - area_intersection\n","\treturn area_union\n","\n","\n","def intersection(ai, bi):\n","\tx = max(ai[0], bi[0])\n","\ty = max(ai[1], bi[1])\n","\tw = min(ai[2], bi[2]) - x\n","\th = min(ai[3], bi[3]) - y\n","\tif w < 0 or h < 0:\n","\t\treturn 0\n","\treturn w*h\n","\n","\n","def iou(a, b):\n","\t# a and b should be (x1,y1,x2,y2)\n","\n","\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n","\t\treturn 0.0\n","\n","\tarea_i = intersection(a, b)\n","\tarea_u = union(a, b, area_i)\n","\n","\treturn float(area_i) / float(area_u + 1e-6)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rcRlzqZudKkd"},"source":["#### Calculate the rpn for all anchors of all images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"daPsCZtrdK3S","colab":{}},"source":["def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n","\t\"\"\"(Important part!) Calculate the rpn for all anchors \n","\t\tIf feature map has shape 38x50=1900, there are 1900x9=17100 potential anchors\n","\t\n","\tArgs:\n","\t\tC: config\n","\t\timg_data: augmented image data\n","\t\twidth: original image width (e.g. 600)\n","\t\theight: original image height (e.g. 800)\n","\t\tresized_width: resized image width according to C.im_size (e.g. 300)\n","\t\tresized_height: resized image height according to C.im_size (e.g. 400)\n","\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n","\n","\tReturns:\n","\t\ty_rpn_cls: list(num_bboxes, y_is_box_valid + y_rpn_overlap)\n","\t\t\ty_is_box_valid: 0 or 1 (0 means the box is invalid, 1 means the box is valid)\n","\t\t\ty_rpn_overlap: 0 or 1 (0 means the box is not an object, 1 means the box is an object)\n","\t\ty_rpn_regr: list(num_bboxes, 4*y_rpn_overlap + y_rpn_regr)\n","\t\t\ty_rpn_regr: x1,y1,x2,y2 bunding boxes coordinates\n","\t\"\"\"\n","\tdownscale = float(C.rpn_stride) \n","\tanchor_sizes = C.anchor_box_scales   # 128, 256, 512\n","\tanchor_ratios = C.anchor_box_ratios  # 1:1, 1:2*sqrt(2), 2*sqrt(2):1\n","\tnum_anchors = len(anchor_sizes) * len(anchor_ratios) # 3x3=9\n","\n","\t# calculate the output map size based on the network architecture\n","\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n","\n","\tn_anchratios = len(anchor_ratios)    # 3\n","\t\n","\t# initialise empty output objectives\n","\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n","\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n","\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n","\n","\tnum_bboxes = len(img_data['bboxes'])\n","\n","\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n","\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n","\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n","\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n","\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n","\n","\t# get the GT box coordinates, and resize to account for image resizing\n","\tgta = np.zeros((num_bboxes, 4))\n","\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n","\t\t# get the GT box coordinates, and resize to account for image resizing\n","\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n","\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n","\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n","\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n","\t\n","\t# rpn ground truth\n","\n","\tfor anchor_size_idx in range(len(anchor_sizes)):\n","\t\tfor anchor_ratio_idx in range(n_anchratios):\n","\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n","\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n","\t\t\t\n","\t\t\tfor ix in range(output_width):\t\t\t\t\t\n","\t\t\t\t# x-coordinates of the current anchor box\t\n","\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n","\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n","\t\t\t\t\n","\t\t\t\t# ignore boxes that go across image boundaries\t\t\t\t\t\n","\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n","\t\t\t\t\tcontinue\n","\t\t\t\t\t\n","\t\t\t\tfor jy in range(output_height):\n","\n","\t\t\t\t\t# y-coordinates of the current anchor box\n","\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n","\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n","\n","\t\t\t\t\t# ignore boxes that go across image boundaries\n","\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n","\t\t\t\t\t\tcontinue\n","\n","\t\t\t\t\t# bbox_type indicates whether an anchor should be a target\n","\t\t\t\t\t# Initialize with 'negative'\n","\t\t\t\t\tbbox_type = 'neg'\n","\n","\t\t\t\t\t# this is the best IOU for the (x,y) coord and the current anchor\n","\t\t\t\t\t# note that this is different from the best IOU for a GT bbox\n","\t\t\t\t\tbest_iou_for_loc = 0.0\n","\n","\t\t\t\t\tfor bbox_num in range(num_bboxes):\n","\t\t\t\t\t\t\n","\t\t\t\t\t\t# get IOU of the current GT box and the current anchor box\n","\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n","\t\t\t\t\t\t# calculate the regression targets if they will be needed\n","\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n","\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n","\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n","\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n","\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n","\n","\t\t\t\t\t\t\t# x,y are the center point of ground-truth bbox\n","\t\t\t\t\t\t\t# xa,ya are the center point of anchor bbox (xa=downscale * (ix + 0.5); ya=downscale * (iy+0.5))\n","\t\t\t\t\t\t\t# w,h are the width and height of ground-truth bbox\n","\t\t\t\t\t\t\t# wa,ha are the width and height of anchor bboxe\n","\t\t\t\t\t\t\t# tx = (x - xa) / wa\n","\t\t\t\t\t\t\t# ty = (y - ya) / ha\n","\t\t\t\t\t\t\t# tw = log(w / wa)\n","\t\t\t\t\t\t\t# th = log(h / ha)\n","\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n","\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n","\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n","\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n","\t\t\t\t\t\t\n","\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n","\n","\t\t\t\t\t\t\t# all GT boxes should be mapped to an anchor box, so we keep track of which anchor box was best\n","\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n","\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n","\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n","\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n","\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n","\n","\t\t\t\t\t\t\t# we set the anchor to positive if the IOU is >0.7 (it does not matter if there was another better box, it just indicates overlap)\n","\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n","\t\t\t\t\t\t\t\tbbox_type = 'pos'\n","\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n","\t\t\t\t\t\t\t\t# we update the regression layer target if this IOU is the best for the current (x,y) and anchor position\n","\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n","\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n","\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n","\n","\t\t\t\t\t\t\t# if the IOU is >0.3 and <0.7, it is ambiguous and no included in the objective\n","\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n","\t\t\t\t\t\t\t\t# gray zone between neg and pos\n","\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n","\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n","\n","\t\t\t\t\t# turn on or off outputs depending on IOUs\n","\t\t\t\t\tif bbox_type == 'neg':\n","\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n","\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n","\t\t\t\t\telif bbox_type == 'neutral':\n","\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n","\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n","\t\t\t\t\telif bbox_type == 'pos':\n","\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n","\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n","\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n","\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n","\n","\t# we ensure that every bbox has at least one positive RPN region\n","\n","\tfor idx in range(num_anchors_for_bbox.shape[0]):\n","\t\tif num_anchors_for_bbox[idx] == 0:\n","\t\t\t# no box with an IOU greater than zero ...\n","\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n","\t\t\t\tcontinue\n","\t\t\ty_is_box_valid[\n","\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n","\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n","\t\t\ty_rpn_overlap[\n","\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n","\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n","\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n","\t\t\ty_rpn_regr[\n","\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n","\n","\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n","\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n","\n","\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n","\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n","\n","\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n","\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n","\n","\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n","\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n","\n","\tnum_pos = len(pos_locs[0])\n","\n","\t# one issue is that the RPN has many more negative than positive regions, so we turn off some of the negative\n","\t# regions. We also limit it to 256 regions.\n","\tnum_regions = 256\n","\n","\tif len(pos_locs[0]) > num_regions/2:\n","\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n","\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n","\t\tnum_pos = num_regions/2\n","\n","\tif len(neg_locs[0]) + num_pos > num_regions:\n","\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n","\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n","\n","\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n","\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n","\n","\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr), num_pos"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"3qGAalfJB8zz"},"source":["#### Get new image size and augment the image"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HKhSFbmB2RTo","colab":{}},"source":["def get_new_img_size(width, height, img_min_side=300):\n","\tif width <= height:\n","\t\tf = float(img_min_side) / width\n","\t\tresized_height = int(f * height)\n","\t\tresized_width = img_min_side\n","\telse:\n","\t\tf = float(img_min_side) / height\n","\t\tresized_width = int(f * width)\n","\t\tresized_height = img_min_side\n","\n","\treturn resized_width, resized_height\n","\n","def augment(img_data, config, augment=True):\n","\tassert 'filepath' in img_data\n","\tassert 'bboxes' in img_data\n","\tassert 'width' in img_data\n","\tassert 'height' in img_data\n","\n","\timg_data_aug = copy.deepcopy(img_data)\n","\n","\timg = cv2.imread(img_data_aug['filepath'])\n","\n","\tif augment:\n","\t\trows, cols = img.shape[:2]\n","\n","\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n","\t\t\timg = cv2.flip(img, 1)\n","\t\t\tfor bbox in img_data_aug['bboxes']:\n","\t\t\t\tx1 = bbox['x1']\n","\t\t\t\tx2 = bbox['x2']\n","\t\t\t\tbbox['x2'] = cols - x1\n","\t\t\t\tbbox['x1'] = cols - x2\n","\n","\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n","\t\t\timg = cv2.flip(img, 0)\n","\t\t\tfor bbox in img_data_aug['bboxes']:\n","\t\t\t\ty1 = bbox['y1']\n","\t\t\t\ty2 = bbox['y2']\n","\t\t\t\tbbox['y2'] = rows - y1\n","\t\t\t\tbbox['y1'] = rows - y2\n","\n","\t\tif config.rot_90:\n","\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n","\t\t\tif angle == 270:\n","\t\t\t\timg = np.transpose(img, (1,0,2))\n","\t\t\t\timg = cv2.flip(img, 0)\n","\t\t\telif angle == 180:\n","\t\t\t\timg = cv2.flip(img, -1)\n","\t\t\telif angle == 90:\n","\t\t\t\timg = np.transpose(img, (1,0,2))\n","\t\t\t\timg = cv2.flip(img, 1)\n","\t\t\telif angle == 0:\n","\t\t\t\tpass\n","\n","\t\t\tfor bbox in img_data_aug['bboxes']:\n","\t\t\t\tx1 = bbox['x1']\n","\t\t\t\tx2 = bbox['x2']\n","\t\t\t\ty1 = bbox['y1']\n","\t\t\t\ty2 = bbox['y2']\n","\t\t\t\tif angle == 270:\n","\t\t\t\t\tbbox['x1'] = y1\n","\t\t\t\t\tbbox['x2'] = y2\n","\t\t\t\t\tbbox['y1'] = cols - x2\n","\t\t\t\t\tbbox['y2'] = cols - x1\n","\t\t\t\telif angle == 180:\n","\t\t\t\t\tbbox['x2'] = cols - x1\n","\t\t\t\t\tbbox['x1'] = cols - x2\n","\t\t\t\t\tbbox['y2'] = rows - y1\n","\t\t\t\t\tbbox['y1'] = rows - y2\n","\t\t\t\telif angle == 90:\n","\t\t\t\t\tbbox['x1'] = rows - y2\n","\t\t\t\t\tbbox['x2'] = rows - y1\n","\t\t\t\t\tbbox['y1'] = x1\n","\t\t\t\t\tbbox['y2'] = x2        \n","\t\t\t\telif angle == 0:\n","\t\t\t\t\tpass\n","\n","\timg_data_aug['width'] = img.shape[1]\n","\timg_data_aug['height'] = img.shape[0]\n","\treturn img_data_aug, img"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0712o8CXkyh1"},"source":["#### Generate the ground_truth anchors"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TvsEv3RIk0cF","colab":{}},"source":["def get_anchor_gt(all_img_data, C, img_length_calc_function, mode='train'):\n","\t\"\"\" Yield the ground-truth anchors as Y (labels)\n","\t\t\n","\tArgs:\n","\t\tall_img_data: list(filepath, width, height, list(bboxes))\n","\t\tC: config\n","\t\timg_length_calc_function: function to calculate final layer's feature map (of base model) size according to input image size\n","\t\tmode: 'train' or 'test'; 'train' mode need augmentation\n","\n","\tReturns:\n","\t\tx_img: image data after resized and scaling (smallest size = 300px)\n","\t\tY: [y_rpn_cls, y_rpn_regr]\n","\t\timg_data_aug: augmented image data (original image with augmentation)\n","\t\tdebug_img: show image for debug\n","\t\tnum_pos: show number of positive anchors for debug\n","\t\"\"\"\n","\twhile True:\n","\n","\t\tfor img_data in all_img_data:\n","\t\t\ttry:\n","\n","\t\t\t\t# read in image, and optionally add augmentation\n","\n","\t\t\t\tif mode == 'train':\n","\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=True)\n","\t\t\t\telse:\n","\t\t\t\t\timg_data_aug, x_img = augment(img_data, C, augment=False)\n","\n","\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n","\t\t\t\t(rows, cols, _) = x_img.shape\n","\n","\t\t\t\tassert cols == width\n","\t\t\t\tassert rows == height\n","\n","\t\t\t\t# get image dimensions for resizing\n","\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n","\n","\t\t\t\t# resize the image so that smalles side is length = 300px\n","\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n","\t\t\t\tdebug_img = x_img.copy()\n","\n","\t\t\t\ttry:\n","\t\t\t\t\ty_rpn_cls, y_rpn_regr, num_pos = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n","\t\t\t\texcept:\n","\t\t\t\t\tcontinue\n","\n","\t\t\t\t# Zero-center by mean pixel, and preprocess image\n","\n","\t\t\t\tx_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n","\t\t\t\tx_img = x_img.astype(np.float32)\n","\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n","\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n","\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n","\t\t\t\tx_img /= C.img_scaling_factor\n","\n","\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n","\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n","\n","\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n","\n","\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n","\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n","\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n","\n","\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug, debug_img, num_pos\n","\n","\t\t\texcept Exception as e:\n","\t\t\t\tprint(e)\n","\t\t\t\tcontinue"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"FZAAMEH4uqu9"},"source":["#### Define loss functions for all four outputs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"CyLxnL4_uvmr","colab":{}},"source":["lambda_rpn_regr = 1.0\n","lambda_rpn_class = 1.0\n","\n","lambda_cls_regr = 1.0\n","lambda_cls_class = 1.0\n","\n","epsilon = 1e-4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tvGfH6m3yu0_","colab":{}},"source":["def rpn_loss_regr(num_anchors):\n","    \"\"\"Loss function for rpn regression\n","    Args:\n","        num_anchors: number of anchors (9 in here)\n","    Returns:\n","        Smooth L1 loss function \n","                           0.5*x*x (if x_abs < 1)\n","                           x_abx - 0.5 (otherwise)\n","    \"\"\"\n","    def rpn_loss_regr_fixed_num(y_true, y_pred):\n","\n","        # x is the difference between true value and predicted vaue\n","        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n","\n","        # absolute value of x\n","        x_abs = K.abs(x)\n","\n","        # If x_abs <= 1.0, x_bool = 1\n","        x_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n","\n","        return lambda_rpn_regr * K.sum(\n","            y_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n","\n","    return rpn_loss_regr_fixed_num\n","\n","\n","def rpn_loss_cls(num_anchors):\n","    \"\"\"Loss function for rpn classification\n","    Args:\n","        num_anchors: number of anchors (9 in here)\n","        y_true[:, :, :, :9]: [0,1,0,0,0,0,0,1,0] means only the second and the eighth box is valid which contains pos or neg anchor => isValid\n","        y_true[:, :, :, 9:]: [0,1,0,0,0,0,0,0,0] means the second box is pos and eighth box is negative\n","    Returns:\n","        lambda * sum((binary_crossentropy(isValid*y_pred,y_true))) / N\n","    \"\"\"\n","    def rpn_loss_cls_fixed_num(y_true, y_pred):\n","\n","            return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n","\n","    return rpn_loss_cls_fixed_num\n","\n","\n","def class_loss_regr(num_classes):\n","    \"\"\"Loss function for rpn regression\n","    Args:\n","        num_anchors: number of anchors (9 in here)\n","    Returns:\n","        Smooth L1 loss function \n","                           0.5*x*x (if x_abs < 1)\n","                           x_abx - 0.5 (otherwise)\n","    \"\"\"\n","    def class_loss_regr_fixed_num(y_true, y_pred):\n","        x = y_true[:, :, 4*num_classes:] - y_pred\n","        x_abs = K.abs(x)\n","        x_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n","        return lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n","    return class_loss_regr_fixed_num\n","\n","\n","def class_loss_cls(y_true, y_pred):\n","    return lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5cX0N4VDl4zS","colab":{}},"source":["def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n","    # code used from here: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n","    # if there are no boxes, return an empty list\n","\n","    # Process explanation:\n","    #   Step 1: Sort the probs list\n","    #   Step 2: Find the larget prob 'Last' in the list and save it to the pick list\n","    #   Step 3: Calculate the IoU with 'Last' box and other boxes in the list. If the IoU is larger than overlap_threshold, delete the box from list\n","    #   Step 4: Repeat step 2 and step 3 until there is no item in the probs list \n","    if len(boxes) == 0:\n","        return []\n","\n","    # grab the coordinates of the bounding boxes\n","    x1 = boxes[:, 0]\n","    y1 = boxes[:, 1]\n","    x2 = boxes[:, 2]\n","    y2 = boxes[:, 3]\n","\n","    np.testing.assert_array_less(x1, x2)\n","    np.testing.assert_array_less(y1, y2)\n","\n","    # if the bounding boxes integers, convert them to floats --\n","    # this is important since we'll be doing a bunch of divisions\n","    if boxes.dtype.kind == \"i\":\n","        boxes = boxes.astype(\"float\")\n","\n","    # initialize the list of picked indexes\t\n","    pick = []\n","\n","    # calculate the areas\n","    area = (x2 - x1) * (y2 - y1)\n","\n","    # sort the bounding boxes \n","    idxs = np.argsort(probs)\n","\n","    # keep looping while some indexes still remain in the indexes\n","    # list\n","    while len(idxs) > 0:\n","        # grab the last index in the indexes list and add the\n","        # index value to the list of picked indexes\n","        last = len(idxs) - 1\n","        i = idxs[last]\n","        pick.append(i)\n","\n","        # find the intersection\n","\n","        xx1_int = np.maximum(x1[i], x1[idxs[:last]])\n","        yy1_int = np.maximum(y1[i], y1[idxs[:last]])\n","        xx2_int = np.minimum(x2[i], x2[idxs[:last]])\n","        yy2_int = np.minimum(y2[i], y2[idxs[:last]])\n","\n","        ww_int = np.maximum(0, xx2_int - xx1_int)\n","        hh_int = np.maximum(0, yy2_int - yy1_int)\n","\n","        area_int = ww_int * hh_int\n","\n","        # find the union\n","        area_union = area[i] + area[idxs[:last]] - area_int\n","\n","        # compute the ratio of overlap\n","        overlap = area_int/(area_union + 1e-6)\n","\n","        # delete all indexes from the index list that have\n","        idxs = np.delete(idxs, np.concatenate(([last],\n","            np.where(overlap > overlap_thresh)[0])))\n","\n","        if len(pick) >= max_boxes:\n","            break\n","\n","    # return only the bounding boxes that were picked using the integer data type\n","    boxes = boxes[pick].astype(\"int\")\n","    probs = probs[pick]\n","    return boxes, probs\n","\n","def apply_regr_np(X, T):\n","    \"\"\"Apply regression layer to all anchors in one feature map\n","\n","    Args:\n","        X: shape=(4, 18, 25) the current anchor type for all points in the feature map\n","        T: regression layer shape=(4, 18, 25)\n","\n","    Returns:\n","        X: regressed position and size for current anchor\n","    \"\"\"\n","    try:\n","        x = X[0, :, :]\n","        y = X[1, :, :]\n","        w = X[2, :, :]\n","        h = X[3, :, :]\n","\n","        tx = T[0, :, :]\n","        ty = T[1, :, :]\n","        tw = T[2, :, :]\n","        th = T[3, :, :]\n","\n","        cx = x + w/2.\n","        cy = y + h/2.\n","        cx1 = tx * w + cx\n","        cy1 = ty * h + cy\n","\n","        w1 = np.exp(tw.astype(np.float64)) * w\n","        h1 = np.exp(th.astype(np.float64)) * h\n","        x1 = cx1 - w1/2.\n","        y1 = cy1 - h1/2.\n","\n","        x1 = np.round(x1)\n","        y1 = np.round(y1)\n","        w1 = np.round(w1)\n","        h1 = np.round(h1)\n","        return np.stack([x1, y1, w1, h1])\n","    except Exception as e:\n","        print(e)\n","        return X\n","    \n","def apply_regr(x, y, w, h, tx, ty, tw, th):\n","    # Apply regression to x, y, w and h\n","    try:\n","        cx = x + w/2.\n","        cy = y + h/2.\n","        cx1 = tx * w + cx\n","        cy1 = ty * h + cy\n","        w1 = math.exp(tw) * w\n","        h1 = math.exp(th) * h\n","        x1 = cx1 - w1/2.\n","        y1 = cy1 - h1/2.\n","        x1 = int(round(x1))\n","        y1 = int(round(y1))\n","        w1 = int(round(w1))\n","        h1 = int(round(h1))\n","\n","        return x1, y1, w1, h1\n","\n","    except ValueError:\n","        return x, y, w, h\n","    except OverflowError:\n","        return x, y, w, h\n","    except Exception as e:\n","        print(e)\n","        return x, y, w, h\n","\n","def calc_iou(R, img_data, C, class_mapping):\n","    \"\"\"Converts from (x1,y1,x2,y2) to (x,y,w,h) format\n","\n","    Args:\n","        R: bboxes, probs\n","    \"\"\"\n","    bboxes = img_data['bboxes']\n","    (width, height) = (img_data['width'], img_data['height'])\n","    # get image dimensions for resizing\n","    (resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n","\n","    gta = np.zeros((len(bboxes), 4))\n","\n","    for bbox_num, bbox in enumerate(bboxes):\n","        # get the GT box coordinates, and resize to account for image resizing\n","        # gta[bbox_num, 0] = (40 * (600 / 800)) / 16 = int(round(1.875)) = 2 (x in feature map)\n","        gta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n","        gta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n","        gta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n","        gta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n","\n","    x_roi = []\n","    y_class_num = []\n","    y_class_regr_coords = []\n","    y_class_regr_label = []\n","    IoUs = [] # for debugging only\n","\n","    # R.shape[0]: number of bboxes (=300 from non_max_suppression)\n","    for ix in range(R.shape[0]):\n","        (x1, y1, x2, y2) = R[ix, :]\n","        x1 = int(round(x1))\n","        y1 = int(round(y1))\n","        x2 = int(round(x2))\n","        y2 = int(round(y2))\n","\n","        best_iou = 0.0\n","        best_bbox = -1\n","        # Iterate through all the ground-truth bboxes to calculate the iou\n","        for bbox_num in range(len(bboxes)):\n","            curr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n","\n","            # Find out the corresponding ground-truth bbox_num with larget iou\n","            if curr_iou > best_iou:\n","                best_iou = curr_iou\n","                best_bbox = bbox_num\n","\n","        if best_iou < C.classifier_min_overlap:\n","                continue\n","        else:\n","            w = x2 - x1\n","            h = y2 - y1\n","            x_roi.append([x1, y1, w, h])\n","            IoUs.append(best_iou)\n","\n","            if C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n","                # hard negative example\n","                cls_name = 'bg'\n","            elif C.classifier_max_overlap <= best_iou:\n","                cls_name = bboxes[best_bbox]['class']\n","                cxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n","                cyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n","\n","                cx = x1 + w / 2.0\n","                cy = y1 + h / 2.0\n","\n","                tx = (cxg - cx) / float(w)\n","                ty = (cyg - cy) / float(h)\n","                tw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n","                th = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n","            else:\n","                print('roi = {}'.format(best_iou))\n","                raise RuntimeError\n","\n","        class_num = class_mapping[cls_name]\n","        class_label = len(class_mapping) * [0]\n","        class_label[class_num] = 1\n","        y_class_num.append(copy.deepcopy(class_label))\n","        coords = [0] * 4 * (len(class_mapping) - 1)\n","        labels = [0] * 4 * (len(class_mapping) - 1)\n","        if cls_name != 'bg':\n","            label_pos = 4 * class_num\n","            sx, sy, sw, sh = C.classifier_regr_std\n","            coords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n","            labels[label_pos:4+label_pos] = [1, 1, 1, 1]\n","            y_class_regr_coords.append(copy.deepcopy(coords))\n","            y_class_regr_label.append(copy.deepcopy(labels))\n","        else:\n","            y_class_regr_coords.append(copy.deepcopy(coords))\n","            y_class_regr_label.append(copy.deepcopy(labels))\n","\n","    if len(x_roi) == 0:\n","        return None, None, None, None\n","\n","    # bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n","    X = np.array(x_roi)\n","    # one hot code for bboxes from above => x_roi (X)\n","    Y1 = np.array(y_class_num)\n","    # corresponding labels and corresponding gt bboxes\n","    Y2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n","\n","    return np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0), IoUs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vT6X-fqJ1RSl","colab":{}},"source":["def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n","\t\"\"\"Convert rpn layer to roi bboxes\n","\n","\tArgs: (num_anchors = 9)\n","\t\trpn_layer: output layer for rpn classification \n","\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n","\t\t\tMight be (1, 18, 25, 18) if resized image is 400 width and 300\n","\t\tregr_layer: output layer for rpn regression\n","\t\t\tshape (1, feature_map.height, feature_map.width, num_anchors)\n","\t\t\tMight be (1, 18, 25, 72) if resized image is 400 width and 300\n","\t\tC: config\n","\t\tuse_regr: Wether to use bboxes regression in rpn\n","\t\tmax_boxes: max bboxes number for non-max-suppression (NMS)\n","\t\toverlap_thresh: If iou in NMS is larger than this threshold, drop the box\n","\n","\tReturns:\n","\t\tresult: boxes from non-max-suppression (shape=(300, 4))\n","\t\t\tboxes: coordinates for bboxes (on the feature map)\n","\t\"\"\"\n","\tregr_layer = regr_layer / C.std_scaling\n","\n","\tanchor_sizes = C.anchor_box_scales   # (3 in here)\n","\tanchor_ratios = C.anchor_box_ratios  # (3 in here)\n","\n","\tassert rpn_layer.shape[0] == 1\n","\n","\t(rows, cols) = rpn_layer.shape[1:3]\n","\n","\tcurr_layer = 0\n","\n","\t# A.shape = (4, feature_map.height, feature_map.width, num_anchors) \n","\t# Might be (4, 18, 25, 18) if resized image is 400 width and 300\n","\t# A is the coordinates for 9 anchors for every point in the feature map \n","\t# => all 18x25x9=4050 anchors cooridnates\n","\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n","\n","\tfor anchor_size in anchor_sizes:\n","\t\tfor anchor_ratio in anchor_ratios:\n","\t\t\t# anchor_x = (128 * 1) / 16 = 8  => width of current anchor\n","\t\t\t# anchor_y = (128 * 2) / 16 = 16 => height of current anchor\n","\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n","\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n","\t\t\t\n","\t\t\t# curr_layer: 0~8 (9 anchors)\n","\t\t\t# the Kth anchor of all position in the feature map (9th in total)\n","\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4] # shape => (18, 25, 4)\n","\t\t\tregr = np.transpose(regr, (2, 0, 1)) # shape => (4, 18, 25)\n","\n","\t\t\t# Create 18x25 mesh grid\n","\t\t\t# For every point in x, there are all the y points and vice versa\n","\t\t\t# X.shape = (18, 25)\n","\t\t\t# Y.shape = (18, 25)\n","\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n","\n","\t\t\t# Calculate anchor position and size for each feature map point\n","\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2 # Top left x coordinate\n","\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2 # Top left y coordinate\n","\t\t\tA[2, :, :, curr_layer] = anchor_x       # width of current anchor\n","\t\t\tA[3, :, :, curr_layer] = anchor_y       # height of current anchor\n","\n","\t\t\t# Apply regression to x, y, w and h if there is rpn regression layer\n","\t\t\tif use_regr:\n","\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n","\n","\t\t\t# Avoid width and height exceeding 1\n","\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n","\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n","\n","\t\t\t# Convert (x, y , w, h) to (x1, y1, x2, y2)\n","\t\t\t# x1, y1 is top left coordinate\n","\t\t\t# x2, y2 is bottom right coordinate\n","\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n","\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n","\n","\t\t\t# Avoid bboxes drawn outside the feature map\n","\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n","\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n","\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n","\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n","\n","\t\t\tcurr_layer += 1\n","\n","\tall_boxes = np.reshape(A.transpose((0, 3, 1, 2)), (4, -1)).transpose((1, 0))  # shape=(4050, 4)\n","\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))                   # shape=(4050,)\n","\n","\tx1 = all_boxes[:, 0]\n","\ty1 = all_boxes[:, 1]\n","\tx2 = all_boxes[:, 2]\n","\ty2 = all_boxes[:, 3]\n","\n","\t# Find out the bboxes which is illegal and delete them from bboxes list\n","\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n","\n","\tall_boxes = np.delete(all_boxes, idxs, 0)\n","\tall_probs = np.delete(all_probs, idxs, 0)\n","\n","\t# Apply non_max_suppression\n","\t# Only extract the bboxes. Don't need rpn probs in the later process\n","\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n","\n","\treturn result"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Kk14GTaNmqoo"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oNsi6HtyJPSb"},"source":["\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"TVmMqXE5x70U"},"source":["### Start training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C66bqGuOq7w6","colab":{}},"source":["base_path = './'\n","\n","train_path =  'annotation.txt' # Training data (annotation file)\n","\n","num_rois = 4 # Number of RoIs to process at once.\n","\n","# Augmentation flag\n","horizontal_flips = True # Augment with horizontal flips in training. \n","vertical_flips = True   # Augment with vertical flips in training. \n","rot_90 = True           # Augment with 90 degree rotations in training. \n","\n","output_weight_path = os.path.join(base_path, 'model/model_frcnn_vgg.hdf5')\n","\n","record_path = os.path.join(base_path, 'model/record.csv') # Record data (used to save the losses, classification accuracy and mean average precision)\n","\n","base_weight_path = os.path.join(base_path, 'model/vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n","\n","config_output_filename = os.path.join(base_path, 'model_vgg_config.pickle')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J3oAmbbEutH0","colab":{}},"source":["# Create the config\n","C = Config()\n","\n","C.use_horizontal_flips = horizontal_flips\n","C.use_vertical_flips = vertical_flips\n","C.rot_90 = rot_90\n","\n","C.record_path = record_path\n","C.model_path = output_weight_path\n","C.num_rois = num_rois\n","\n","C.base_net_weights = base_weight_path"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558100535853,"user_tz":-120,"elapsed":1014411,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"yiEaAmb-x-so","outputId":"0f30679e-4e3f-417b-cd05-33a79a74e371","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["#--------------------------------------------------------#\n","# This step will spend some time to load the data        #\n","#--------------------------------------------------------#\n","st = time.time()\n","train_imgs, classes_count, class_mapping = get_data(train_path)\n","print()\n","print('Spend %0.2f mins to load the data' % ((time.time()-st)/60) )"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Parsing annotation files\n","idx=2224\n","Spend 16.90 mins to load the data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558100539296,"user_tz":-120,"elapsed":881,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"x-nuSdC56GsK","outputId":"f9e393d5-6ef2-4a3c-a616-99e71933b7b5","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["if 'bg' not in classes_count:\n","\tclasses_count['bg'] = 0\n","\tclass_mapping['bg'] = len(class_mapping)\n","# e.g.\n","#    classes_count: {'Car': 2383, 'Mobile phone': 1108, 'Person': 3745, 'bg': 0}\n","#    class_mapping: {'Person': 0, 'Car': 1, 'Mobile phone': 2, 'bg': 3}\n","C.class_mapping = class_mapping\n","\n","print('Training images per class:')\n","pprint.pprint(classes_count)\n","print('Num classes (including bg) = {}'.format(len(classes_count)))\n","print(class_mapping)\n","\n","# Save the configuration\n","with open(config_output_filename, 'wb') as config_f:\n","\tpickle.dump(C,config_f)\n","\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Training images per class:\n","{'1_HYSE': 703, '2_SEI': 656, '3_TORSK': 800, '4_LASK': 65, 'bg': 0}\n","Num classes (including bg) = 5\n","{'1_HYSE': 0, '2_SEI': 1, '3_TORSK': 2, '4_LASK': 3, 'bg': 4}\n","Config has been written to ./model_vgg_config.pickle, and can be loaded when testing to ensure correct results\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558100544786,"user_tz":-120,"elapsed":1259,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"LFlq36Sx4F4O","outputId":"164b8196-f6f1-4a48-c254-09ac2074b9dd","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Shuffle the images with seed\n","random.seed(1)\n","random.shuffle(train_imgs)\n","\n","print('Num train samples (images) {}'.format(len(train_imgs)))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Num train samples (images) 2223\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GXIV1uXyBo3v","colab":{}},"source":["# Get train data generator which generate X, Y, image_data\n","data_gen_train = get_anchor_gt(train_imgs, C, get_img_output_length, mode='train')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y_yM5jkKqM1G"},"source":["#### Explore 'data_gen_train'\n","\n","data_gen_train is an **generator**, so we get the data by calling **next(data_gen_train)**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"nIDnio1UlRHi","colab":{}},"source":["X, Y, image_data, debug_img, debug_num_pos = next(data_gen_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558100561549,"user_tz":-120,"elapsed":1031,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"dZXoJ2e3l2Ey","outputId":"5ab68d5d-59cf-4bdf-909f-bc7d5a058138","colab":{"base_uri":"https://localhost:8080/","height":928}},"source":["print('Original image: height=%d width=%d'%(image_data['height'], image_data['width']))\n","print('Resized image:  height=%d width=%d C.im_size=%d'%(X.shape[1], X.shape[2], C.im_size))\n","print('Feature map size: height=%d width=%d C.rpn_stride=%d'%(Y[0].shape[1], Y[0].shape[2], C.rpn_stride))\n","print(X.shape)\n","print(str(len(Y))+\" includes 'y_rpn_cls' and 'y_rpn_regr'\")\n","print('Shape of y_rpn_cls {}'.format(Y[0].shape))\n","print('Shape of y_rpn_regr {}'.format(Y[1].shape))\n","print(image_data)\n","\n","print('Number of positive anchors for this image: %d' % (debug_num_pos))\n","if debug_num_pos==0:\n","    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[2]/image_data['height']), image_data['bboxes'][0]['x2']*(X.shape[2]/image_data['height'])\n","    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[1]/image_data['width']), image_data['bboxes'][0]['y2']*(X.shape[1]/image_data['width'])\n","    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n","\n","    img = debug_img.copy()\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    color = (0, 255, 0)\n","    cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n","    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n","    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n","\n","    plt.grid()\n","    plt.imshow(img)\n","    plt.show()\n","else:\n","    cls = Y[0][0]\n","    pos_cls = np.where(cls==1)\n","    print(pos_cls)\n","    regr = Y[1][0]\n","    pos_regr = np.where(regr==1)\n","    print(pos_regr)\n","    print('y_rpn_cls for possible pos anchor: {}'.format(cls[pos_cls[0][0],pos_cls[1][0],:]))\n","    print('y_rpn_regr for positive anchor: {}'.format(regr[pos_regr[0][0],pos_regr[1][0],:]))\n","\n","    gt_x1, gt_x2 = image_data['bboxes'][0]['x1']*(X.shape[2]/image_data['width']), image_data['bboxes'][0]['x2']*(X.shape[2]/image_data['width'])\n","    gt_y1, gt_y2 = image_data['bboxes'][0]['y1']*(X.shape[1]/image_data['height']), image_data['bboxes'][0]['y2']*(X.shape[1]/image_data['height'])\n","    gt_x1, gt_y1, gt_x2, gt_y2 = int(gt_x1), int(gt_y1), int(gt_x2), int(gt_y2)\n","\n","    img = debug_img.copy()\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    color = (0, 255, 0)\n","    #   cv2.putText(img, 'gt bbox', (gt_x1, gt_y1-5), cv2.FONT_HERSHEY_DUPLEX, 0.7, color, 1)\n","    cv2.rectangle(img, (gt_x1, gt_y1), (gt_x2, gt_y2), color, 2)\n","    cv2.circle(img, (int((gt_x1+gt_x2)/2), int((gt_y1+gt_y2)/2)), 3, color, -1)\n","\n","    # Add text\n","    textLabel = 'gt bbox'\n","    (retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,0.5,1)\n","    textOrg = (gt_x1, gt_y1+5)\n","    cv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n","    cv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n","    cv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 0.5, (0, 0, 0), 1)\n","\n","    # Draw positive anchors according to the y_rpn_regr\n","    for i in range(debug_num_pos):\n","\n","        color = (100+i*(155/4), 0, 100+i*(155/4))\n","\n","        idx = pos_regr[2][i*4]/4\n","        anchor_size = C.anchor_box_scales[int(idx/3)]\n","        anchor_ratio = C.anchor_box_ratios[2-int((idx+1)%3)]\n","\n","        center = (pos_regr[1][i*4]*C.rpn_stride, pos_regr[0][i*4]*C.rpn_stride)\n","        print('Center position of positive anchor: ', center)\n","        cv2.circle(img, center, 3, color, -1)\n","        anc_w, anc_h = anchor_size*anchor_ratio[0], anchor_size*anchor_ratio[1]\n","        cv2.rectangle(img, (center[0]-int(anc_w/2), center[1]-int(anc_h/2)), (center[0]+int(anc_w/2), center[1]+int(anc_h/2)), color, 2)\n","#         cv2.putText(img, 'pos anchor bbox '+str(i+1), (center[0]-int(anc_w/2), center[1]-int(anc_h/2)-5), cv2.FONT_HERSHEY_DUPLEX, 0.5, color, 1)\n","\n","print('Green bboxes is ground-truth bbox. Others are positive anchors')\n","plt.figure(figsize=(8,8))\n","plt.grid()\n","plt.imshow(img)\n","plt.show()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Original image: height=292 width=159\n","Resized image:  height=550 width=300 C.im_size=300\n","Feature map size: height=34 width=18 C.rpn_stride=16\n","(1, 550, 300, 3)\n","2 includes 'y_rpn_cls' and 'y_rpn_regr'\n","Shape of y_rpn_cls (1, 34, 18, 18)\n","Shape of y_rpn_regr (1, 34, 18, 72)\n","{'filepath': 'train/RGB_63645102560025.jpg', 'width': 159, 'height': 292, 'bboxes': [{'class': '2_SEI', 'x1': 7, 'x2': 151, 'y1': 14, 'y2': 277}]}\n","Number of positive anchors for this image: 1\n","(array([ 8, 20, 20]), array([ 3, 11, 11]), array([ 4,  7, 16]))\n","(array([20, 20, 20, 20]), array([11, 11, 11, 11]), array([28, 29, 30, 31]))\n","y_rpn_cls for possible pos anchor: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","y_rpn_regr for positive anchor: [ 0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          1.          1.\n","  1.          1.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.          0.          0.\n","  0.          0.          0.          0.         -0.77214724 -0.59597808\n","  1.62435091  1.25426984  0.          0.          0.          0.        ]\n","Center position of positive anchor:  (176, 320)\n","Green bboxes is ground-truth bbox. Others are positive anchors\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAR8AAAHVCAYAAADIJP+fAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n","text/plain":["<Figure size 576x576 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"i4XSyIoubCMY"},"source":["#### Build the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jODipXFDnDJ0","outputId":"56717458-4f70-4a38-9018-da307835964f","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1558100567434,"user_tz":-120,"elapsed":738,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}}},"source":["input_shape_img = (None, None, 3)\n","\n","img_input = Input(shape=input_shape_img)\n","roi_input = Input(shape=(None, 4))\n","\n","# define the base network (VGG here, can be Resnet50, Inception, etc)\n","shared_layers = nn_base(img_input, trainable=True)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558100582158,"user_tz":-120,"elapsed":12715,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"udTeQMVhfSzw","outputId":"e11809b9-9eb0-442c-d073-e4310d2aa580","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# define the RPN, built on the base layers\n","num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios) # 9\n","rpn = rpn_layer(shared_layers, num_anchors)\n","\n","classifier = classifier_layer(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count))\n","\n","model_rpn = Model(img_input, rpn[:2])\n","model_classifier = Model([img_input, roi_input], classifier)\n","\n","# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n","model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n","\n","# Because the google colab can only run the session several hours one time (then you need to connect again), \n","# we need to save the model and load the model to continue training\n","if not os.path.isfile(C.model_path):\n","    #If this is the begin of the training, load the pre-traind base network such as vgg-16\n","    try:\n","        print('This is the first time of your training')\n","        print('loading weights from {}'.format(C.base_net_weights))\n","        model_rpn.load_weights(C.base_net_weights, by_name=True)\n","        model_classifier.load_weights(C.base_net_weights, by_name=True)\n","    except:\n","        print('Could not load pretrained model weights. https://github.com/fchollet/deep-learning-models/releases/tag/v0.1/' + C.base_net_weights )\n","    \n","    # Create the record.csv file to record losses, acc and mAP\n","    record_df = pd.DataFrame(columns=['mean_overlapping_bboxes', 'class_acc', 'loss_rpn_cls', 'loss_rpn_regr', 'loss_class_cls', 'loss_class_regr', 'curr_loss', 'elapsed_time', 'mAP'])\n","else:\n","    # If this is a continued training, load the trained model from before\n","    print('Continue training based on previous trained model')\n","    print('Loading weights from {}'.format(C.model_path))\n","    model_rpn.load_weights(C.model_path, by_name=True)\n","    model_classifier.load_weights(C.model_path, by_name=True)\n","    \n","    # Load the records\n","    record_df = pd.read_csv(record_path)\n","\n","    r_mean_overlapping_bboxes = record_df['mean_overlapping_bboxes']\n","    r_class_acc = record_df['class_acc']\n","    r_loss_rpn_cls = record_df['loss_rpn_cls']\n","    r_loss_rpn_regr = record_df['loss_rpn_regr']\n","    r_loss_class_cls = record_df['loss_class_cls']\n","    r_loss_class_regr = record_df['loss_class_regr']\n","    r_curr_loss = record_df['curr_loss']\n","    r_elapsed_time = record_df['elapsed_time']\n","    r_mAP = record_df['mAP']\n","\n","    print('Already train %dK batches'% (len(record_df)))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","Continue training based on previous trained model\n","Loading weights from ./model/model_frcnn_vgg.hdf5\n","Already train 30K batches\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-ULrg0V1soIR","colab":{}},"source":["optimizer = Adam(lr=1e-5)\n","optimizer_classifier = Adam(lr=1e-5)\n","model_rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(num_anchors), rpn_loss_regr(num_anchors)])\n","model_classifier.compile(optimizer=optimizer_classifier, loss=[class_loss_cls, class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n","model_all.compile(optimizer='sgd', loss='mae')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Qz2BYzL6sqfu","colab":{}},"source":["# Training setting\n","total_epochs = len(record_df)\n","r_epochs = len(record_df)\n","\n","epoch_length = 1000\n","num_epochs = 40\n","iter_num = 0\n","\n","total_epochs += num_epochs\n","\n","losses = np.zeros((epoch_length, 5))\n","rpn_accuracy_rpn_monitor = []\n","rpn_accuracy_for_epoch = []\n","\n","if len(record_df)==0:\n","    best_loss = np.Inf\n","else:\n","    best_loss = np.min(r_curr_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1558100591574,"user_tz":-120,"elapsed":588,"user":{"displayName":"Robocon Optimar","photoUrl":"","userId":"15750199588120283935"}},"id":"JDysEDQA2DUz","outputId":"4f0e6272-5bcf-4561-86b3-fce08599e339","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(len(record_df))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["30\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1332624,"status":"ok","timestamp":1542188908991,"user":{"displayName":"Yinghan Xu","photoUrl":"https://lh3.googleusercontent.com/-ZH_vkc0a6g0/AAAAAAAAAAI/AAAAAAAAAAc/x8TPjkqmxys/s64/photo.jpg","userId":"13488364327507272606"},"user_tz":-480},"id":"dRXtd5W30DRN","outputId":"69d6dc82-604b-477a-d090-aec7d38deba6","colab":{"base_uri":"https://localhost:8080/","height":4216}},"source":["start_time = time.time()\n","for epoch_num in range(num_epochs):\n","\n","    progbar = generic_utils.Progbar(epoch_length)\n","    print('Epoch {}/{}'.format(r_epochs + 1, total_epochs))\n","    \n","    r_epochs += 1\n","\n","    while True:\n","        try:\n","\n","            if len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n","                mean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n","                rpn_accuracy_rpn_monitor = []\n","#                 print('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n","                if mean_overlapping_bboxes == 0:\n","                    print('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n","\n","            # Generate X (x_img) and label Y ([y_rpn_cls, y_rpn_regr])\n","            X, Y, img_data, debug_img, debug_num_pos = next(data_gen_train)\n","\n","            # Train rpn model and get loss value [_, loss_rpn_cls, loss_rpn_regr]\n","            loss_rpn = model_rpn.train_on_batch(X, Y)\n","\n","            # Get predicted rpn from rpn model [rpn_cls, rpn_regr]\n","            P_rpn = model_rpn.predict_on_batch(X)\n","\n","            # R: bboxes (shape=(300,4))\n","            # Convert rpn layer to roi bboxes\n","            R = rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n","            \n","            # note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n","            # X2: bboxes that iou > C.classifier_min_overlap for all gt bboxes in 300 non_max_suppression bboxes\n","            # Y1: one hot code for bboxes from above => x_roi (X)\n","            # Y2: corresponding labels and corresponding gt bboxes\n","            X2, Y1, Y2, IouS = calc_iou(R, img_data, C, class_mapping)\n","\n","            # If X2 is None means there are no matching bboxes\n","            if X2 is None:\n","                rpn_accuracy_rpn_monitor.append(0)\n","                rpn_accuracy_for_epoch.append(0)\n","                continue\n","            \n","            # Find out the positive anchors and negative anchors\n","            neg_samples = np.where(Y1[0, :, -1] == 1)\n","            pos_samples = np.where(Y1[0, :, -1] == 0)\n","\n","            if len(neg_samples) > 0:\n","                neg_samples = neg_samples[0]\n","            else:\n","                neg_samples = []\n","\n","            if len(pos_samples) > 0:\n","                pos_samples = pos_samples[0]\n","            else:\n","                pos_samples = []\n","\n","            rpn_accuracy_rpn_monitor.append(len(pos_samples))\n","            rpn_accuracy_for_epoch.append((len(pos_samples)))\n","\n","            if C.num_rois > 1:\n","                # If number of positive anchors is larger than 4//2 = 2, randomly choose 2 pos samples\n","                if len(pos_samples) < C.num_rois//2:\n","                    selected_pos_samples = pos_samples.tolist()\n","                else:\n","                    selected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n","                \n","                # Randomly choose (num_rois - num_pos) neg samples\n","                try:\n","                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n","                except:\n","                    selected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n","                \n","                # Save all the pos and neg samples in sel_samples\n","                sel_samples = selected_pos_samples + selected_neg_samples\n","            else:\n","                # in the extreme case where num_rois = 1, we pick a random pos or neg sample\n","                selected_pos_samples = pos_samples.tolist()\n","                selected_neg_samples = neg_samples.tolist()\n","                if np.random.randint(0, 2):\n","                    sel_samples = random.choice(neg_samples)\n","                else:\n","                    sel_samples = random.choice(pos_samples)\n","\n","            # training_data: [X, X2[:, sel_samples, :]]\n","            # labels: [Y1[:, sel_samples, :], Y2[:, sel_samples, :]]\n","            #  X                     => img_data resized image\n","            #  X2[:, sel_samples, :] => num_rois (4 in here) bboxes which contains selected neg and pos\n","            #  Y1[:, sel_samples, :] => one hot encode for num_rois bboxes which contains selected neg and pos\n","            #  Y2[:, sel_samples, :] => labels and gt bboxes for num_rois bboxes which contains selected neg and pos\n","            loss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n","\n","            losses[iter_num, 0] = loss_rpn[1]\n","            losses[iter_num, 1] = loss_rpn[2]\n","\n","            losses[iter_num, 2] = loss_class[1]\n","            losses[iter_num, 3] = loss_class[2]\n","            losses[iter_num, 4] = loss_class[3]\n","\n","            iter_num += 1\n","\n","            progbar.update(iter_num, [('rpn_cls', np.mean(losses[:iter_num, 0])), ('rpn_regr', np.mean(losses[:iter_num, 1])),\n","                                      ('final_cls', np.mean(losses[:iter_num, 2])), ('final_regr', np.mean(losses[:iter_num, 3]))])\n","\n","            if iter_num == epoch_length:\n","                loss_rpn_cls = np.mean(losses[:, 0])\n","                loss_rpn_regr = np.mean(losses[:, 1])\n","                loss_class_cls = np.mean(losses[:, 2])\n","                loss_class_regr = np.mean(losses[:, 3])\n","                class_acc = np.mean(losses[:, 4])\n","\n","                mean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n","                rpn_accuracy_for_epoch = []\n","\n","                if C.verbose:\n","                    print('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n","                    print('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n","                    print('Loss RPN classifier: {}'.format(loss_rpn_cls))\n","                    print('Loss RPN regression: {}'.format(loss_rpn_regr))\n","                    print('Loss Detector classifier: {}'.format(loss_class_cls))\n","                    print('Loss Detector regression: {}'.format(loss_class_regr))\n","                    print('Total loss: {}'.format(loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr))\n","                    print('Elapsed time: {}'.format(time.time() - start_time))\n","                    elapsed_time = (time.time()-start_time)/60\n","\n","                curr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n","                iter_num = 0\n","                start_time = time.time()\n","\n","                if curr_loss < best_loss:\n","                    if C.verbose:\n","                        print('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n","                    best_loss = curr_loss\n","                    model_all.save_weights(C.model_path)\n","\n","                new_row = {'mean_overlapping_bboxes':round(mean_overlapping_bboxes, 3), \n","                           'class_acc':round(class_acc, 3), \n","                           'loss_rpn_cls':round(loss_rpn_cls, 3), \n","                           'loss_rpn_regr':round(loss_rpn_regr, 3), \n","                           'loss_class_cls':round(loss_class_cls, 3), \n","                           'loss_class_regr':round(loss_class_regr, 3), \n","                           'curr_loss':round(curr_loss, 3), \n","                           'elapsed_time':round(elapsed_time, 3), \n","                           'mAP': 0}\n","\n","                record_df = record_df.append(new_row, ignore_index=True)\n","                record_df.to_csv(record_path, index=0)\n","\n","                break\n","\n","        except Exception as e:\n","            print('Exception: {}'.format(e))\n","            continue\n","\n","print('Training complete, exiting.')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 31/70\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","1000/1000 [==============================] - 1608s 2s/step - rpn_cls: 0.1325 - rpn_regr: 0.0836 - final_cls: 0.2254 - final_regr: 0.0701\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.171\n","Classifier accuracy for bounding boxes from RPN: 0.922\n","Loss RPN classifier: 0.11277532713194159\n","Loss RPN regression: 0.0850496595349905\n","Loss Detector classifier: 0.2169021797386522\n","Loss Detector regression: 0.06928071285458282\n","Total loss: 0.4840078792601671\n","Elapsed time: 1608.2534663677216\n","Epoch 32/70\n","1000/1000 [==============================] - 864s 864ms/step - rpn_cls: 0.0973 - rpn_regr: 0.0825 - final_cls: 0.2207 - final_regr: 0.0609\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.127\n","Classifier accuracy for bounding boxes from RPN: 0.91175\n","Loss RPN classifier: 0.10718388022674631\n","Loss RPN regression: 0.08959014090261189\n","Loss Detector classifier: 0.24155465464433656\n","Loss Detector regression: 0.06442574005597271\n","Total loss: 0.5027544158296675\n","Elapsed time: 864.0897073745728\n","Epoch 33/70\n","1000/1000 [==============================] - 607s 607ms/step - rpn_cls: 0.1653 - rpn_regr: 0.0881 - final_cls: 0.1864 - final_regr: 0.0624\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.187\n","Classifier accuracy for bounding boxes from RPN: 0.92175\n","Loss RPN classifier: 0.13319862501784785\n","Loss RPN regression: 0.08419757067811588\n","Loss Detector classifier: 0.19940256995325034\n","Loss Detector regression: 0.06385478508914821\n","Total loss: 0.4806535507383623\n","Elapsed time: 607.323050737381\n","Epoch 34/70\n","1000/1000 [==============================] - 557s 557ms/step - rpn_cls: 0.1315 - rpn_regr: 0.0758 - final_cls: 0.2466 - final_regr: 0.0577\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.106\n","Classifier accuracy for bounding boxes from RPN: 0.911\n","Loss RPN classifier: 0.11732391849933475\n","Loss RPN regression: 0.07642313151116832\n","Loss Detector classifier: 0.2377780385571823\n","Loss Detector regression: 0.06062933118501678\n","Total loss: 0.49215441975270213\n","Elapsed time: 557.3082687854767\n","Epoch 35/70\n","1000/1000 [==============================] - 518s 518ms/step - rpn_cls: 0.1504 - rpn_regr: 0.0853 - final_cls: 0.2352 - final_regr: 0.0562\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.027\n","Classifier accuracy for bounding boxes from RPN: 0.915\n","Loss RPN classifier: 0.16605823520919102\n","Loss RPN regression: 0.08472415751348672\n","Loss Detector classifier: 0.23570055715044144\n","Loss Detector regression: 0.05634614811418578\n","Total loss: 0.542829097987305\n","Elapsed time: 518.3565375804901\n","Epoch 36/70\n","1000/1000 [==============================] - 498s 498ms/step - rpn_cls: 0.1872 - rpn_regr: 0.0744 - final_cls: 0.1975 - final_regr: 0.0613\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.991\n","Classifier accuracy for bounding boxes from RPN: 0.926\n","Loss RPN classifier: 0.14840104457823436\n","Loss RPN regression: 0.0738151113775366\n","Loss Detector classifier: 0.19203764173075616\n","Loss Detector regression: 0.06010815464844927\n","Total loss: 0.4743619523349764\n","Elapsed time: 497.5827338695526\n","Epoch 37/70\n","1000/1000 [==============================] - 478s 478ms/step - rpn_cls: 0.1144 - rpn_regr: 0.0832 - final_cls: 0.2505 - final_regr: 0.0606\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.079\n","Classifier accuracy for bounding boxes from RPN: 0.9135\n","Loss RPN classifier: 0.11241395590294465\n","Loss RPN regression: 0.08309063005238568\n","Loss Detector classifier: 0.23195837612410833\n","Loss Detector regression: 0.06265864938194864\n","Total loss: 0.49012161146138733\n","Elapsed time: 477.93815541267395\n","Epoch 38/70\n","1000/1000 [==============================] - 466s 466ms/step - rpn_cls: 0.0906 - rpn_regr: 0.0751 - final_cls: 0.2246 - final_regr: 0.0578\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.122\n","Classifier accuracy for bounding boxes from RPN: 0.9255\n","Loss RPN classifier: 0.08562501056920815\n","Loss RPN regression: 0.07603816801052744\n","Loss Detector classifier: 0.19761919103513356\n","Loss Detector regression: 0.057524181083776056\n","Total loss: 0.4168065506986452\n","Elapsed time: 465.6021807193756\n","Total loss decreased from 0.461 to 0.4168065506986452, saving weights\n","Epoch 39/70\n","1000/1000 [==============================] - 475s 475ms/step - rpn_cls: 0.1239 - rpn_regr: 0.0806 - final_cls: 0.2126 - final_regr: 0.0589\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.074\n","Classifier accuracy for bounding boxes from RPN: 0.924\n","Loss RPN classifier: 0.11894430071587073\n","Loss RPN regression: 0.08152521573854028\n","Loss Detector classifier: 0.21791139477667457\n","Loss Detector regression: 0.05769191877485719\n","Total loss: 0.47607283000594275\n","Elapsed time: 478.57663798332214\n","Epoch 40/70\n","1000/1000 [==============================] - 468s 468ms/step - rpn_cls: 0.1298 - rpn_regr: 0.0651 - final_cls: 0.2199 - final_regr: 0.0588\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.116\n","Classifier accuracy for bounding boxes from RPN: 0.9145\n","Loss RPN classifier: 0.13187235613033393\n","Loss RPN regression: 0.07136956120075774\n","Loss Detector classifier: 0.21606042602488015\n","Loss Detector regression: 0.058614229848608375\n","Total loss: 0.4779165732045802\n","Elapsed time: 467.7642617225647\n","Epoch 41/70\n","1000/1000 [==============================] - 452s 452ms/step - rpn_cls: 0.1714 - rpn_regr: 0.0708 - final_cls: 0.1965 - final_regr: 0.0597\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.183\n","Classifier accuracy for bounding boxes from RPN: 0.927\n","Loss RPN classifier: 0.12184307627057468\n","Loss RPN regression: 0.07838690917512577\n","Loss Detector classifier: 0.2060937451987411\n","Loss Detector regression: 0.05995044431905262\n","Total loss: 0.46627417496349416\n","Elapsed time: 451.5561451911926\n","Epoch 42/70\n","1000/1000 [==============================] - 450s 450ms/step - rpn_cls: 0.1506 - rpn_regr: 0.0647 - final_cls: 0.2214 - final_regr: 0.0580\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.065\n","Classifier accuracy for bounding boxes from RPN: 0.922\n","Loss RPN classifier: 0.14585139501534594\n","Loss RPN regression: 0.07164569306400154\n","Loss Detector classifier: 0.2120027940942091\n","Loss Detector regression: 0.05706030878424644\n","Total loss: 0.48656019095780306\n","Elapsed time: 450.0321500301361\n","Epoch 43/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.0904 - rpn_regr: 0.0715 - final_cls: 0.1920 - final_regr: 0.0571\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.09\n","Classifier accuracy for bounding boxes from RPN: 0.926\n","Loss RPN classifier: 0.10125901266366148\n","Loss RPN regression: 0.07138091876786712\n","Loss Detector classifier: 0.1978122869917861\n","Loss Detector regression: 0.05977370986132882\n","Total loss: 0.43022592828464357\n","Elapsed time: 450.8939747810364\n","Epoch 44/70\n","1000/1000 [==============================] - 446s 446ms/step - rpn_cls: 0.0807 - rpn_regr: 0.0722 - final_cls: 0.2122 - final_regr: 0.0567\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.994\n","Classifier accuracy for bounding boxes from RPN: 0.91625\n","Loss RPN classifier: 0.08217974154923446\n","Loss RPN regression: 0.07057350896994467\n","Loss Detector classifier: 0.2203565386586488\n","Loss Detector regression: 0.05543464223737828\n","Total loss: 0.4285444314152062\n","Elapsed time: 446.3078725337982\n","Epoch 45/70\n","1000/1000 [==============================] - 452s 452ms/step - rpn_cls: 0.1277 - rpn_regr: 0.0712 - final_cls: 0.1803 - final_regr: 0.0556\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.202\n","Classifier accuracy for bounding boxes from RPN: 0.9305\n","Loss RPN classifier: 0.09534184769879893\n","Loss RPN regression: 0.07142683233559365\n","Loss Detector classifier: 0.1858032526645984\n","Loss Detector regression: 0.056710715959314255\n","Total loss: 0.40928264865830527\n","Elapsed time: 451.55688190460205\n","Total loss decreased from 0.4168065506986452 to 0.40928264865830527, saving weights\n","Epoch 46/70\n","1000/1000 [==============================] - 450s 450ms/step - rpn_cls: 0.1640 - rpn_regr: 0.0845 - final_cls: 0.2366 - final_regr: 0.0561\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.035\n","Classifier accuracy for bounding boxes from RPN: 0.92175\n","Loss RPN classifier: 0.12467914299797975\n","Loss RPN regression: 0.07206445821411762\n","Loss Detector classifier: 0.21405223601653414\n","Loss Detector regression: 0.054114388382993636\n","Total loss: 0.4649102256116252\n","Elapsed time: 458.2194592952728\n","Epoch 47/70\n","1000/1000 [==============================] - 450s 450ms/step - rpn_cls: 0.1326 - rpn_regr: 0.0597 - final_cls: 0.1861 - final_regr: 0.0532\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.985\n","Classifier accuracy for bounding boxes from RPN: 0.9325\n","Loss RPN classifier: 0.1650320882755147\n","Loss RPN regression: 0.06505839523386385\n","Loss Detector classifier: 0.18129912152090402\n","Loss Detector regression: 0.05481442557508126\n","Total loss: 0.4662040306053638\n","Elapsed time: 449.920951128006\n","Epoch 48/70\n","1000/1000 [==============================] - 444s 444ms/step - rpn_cls: 0.1796 - rpn_regr: 0.0691 - final_cls: 0.2177 - final_regr: 0.0564\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.088\n","Classifier accuracy for bounding boxes from RPN: 0.92025\n","Loss RPN classifier: 0.15984681387883062\n","Loss RPN regression: 0.0674834401172775\n","Loss Detector classifier: 0.21516154998769343\n","Loss Detector regression: 0.05748229103558697\n","Total loss: 0.4999740950193885\n","Elapsed time: 444.3796434402466\n","Epoch 49/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.1382 - rpn_regr: 0.0743 - final_cls: 0.1986 - final_regr: 0.0590\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.076\n","Classifier accuracy for bounding boxes from RPN: 0.932\n","Loss RPN classifier: 0.17716510502445343\n","Loss RPN regression: 0.07221847188150787\n","Loss Detector classifier: 0.19080958576409465\n","Loss Detector regression: 0.056075907110935075\n","Total loss: 0.496269069780991\n","Elapsed time: 451.0821762084961\n","Epoch 50/70\n","1000/1000 [==============================] - 447s 447ms/step - rpn_cls: 0.1611 - rpn_regr: 0.0632 - final_cls: 0.1877 - final_regr: 0.0534\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.924\n","Classifier accuracy for bounding boxes from RPN: 0.929\n","Loss RPN classifier: 0.16843775673271216\n","Loss RPN regression: 0.06867557987468899\n","Loss Detector classifier: 0.19696355768175272\n","Loss Detector regression: 0.05433246785844676\n","Total loss: 0.4884093621476006\n","Elapsed time: 446.80625081062317\n","Epoch 51/70\n","1000/1000 [==============================] - 447s 447ms/step - rpn_cls: 0.1760 - rpn_regr: 0.0629 - final_cls: 0.1728 - final_regr: 0.0511\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.043\n","Classifier accuracy for bounding boxes from RPN: 0.93175\n","Loss RPN classifier: 0.15247740549740474\n","Loss RPN regression: 0.0654129479879266\n","Loss Detector classifier: 0.17535906474939655\n","Loss Detector regression: 0.05381459104083478\n","Total loss: 0.4470640092755627\n","Elapsed time: 447.1165292263031\n","Epoch 52/70\n","1000/1000 [==============================] - 446s 446ms/step - rpn_cls: 0.1351 - rpn_regr: 0.0557 - final_cls: 0.1966 - final_regr: 0.0520\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.095\n","Classifier accuracy for bounding boxes from RPN: 0.9285\n","Loss RPN classifier: 0.10315739189520957\n","Loss RPN regression: 0.062316685487494396\n","Loss Detector classifier: 0.19602223737430177\n","Loss Detector regression: 0.05513552932278253\n","Total loss: 0.41663184407978826\n","Elapsed time: 445.8086087703705\n","Epoch 53/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.1749 - rpn_regr: 0.0710 - final_cls: 0.1872 - final_regr: 0.0551\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.097\n","Classifier accuracy for bounding boxes from RPN: 0.9285\n","Loss RPN classifier: 0.16081800128525406\n","Loss RPN regression: 0.06349894889459393\n","Loss Detector classifier: 0.18501058625848965\n","Loss Detector regression: 0.05201158334617503\n","Total loss: 0.4613391197845127\n","Elapsed time: 451.184889793396\n","Epoch 54/70\n","1000/1000 [==============================] - 452s 452ms/step - rpn_cls: 0.1152 - rpn_regr: 0.0624 - final_cls: 0.1823 - final_regr: 0.0535\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.985\n","Classifier accuracy for bounding boxes from RPN: 0.92575\n","Loss RPN classifier: 0.10339366174854304\n","Loss RPN regression: 0.06302528042973427\n","Loss Detector classifier: 0.19339505693414685\n","Loss Detector regression: 0.05401631302316673\n","Total loss: 0.4138303121355909\n","Elapsed time: 452.03814220428467\n","Epoch 55/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.1161 - rpn_regr: 0.0692 - final_cls: 0.1860 - final_regr: 0.0512\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.061\n","Classifier accuracy for bounding boxes from RPN: 0.932\n","Loss RPN classifier: 0.1420367655495531\n","Loss RPN regression: 0.06470100053528222\n","Loss Detector classifier: 0.182529761421305\n","Loss Detector regression: 0.049870116939884614\n","Total loss: 0.439137644446025\n","Elapsed time: 451.45415329933167\n","Epoch 56/70\n","1000/1000 [==============================] - 453s 453ms/step - rpn_cls: 0.1274 - rpn_regr: 0.0589 - final_cls: 0.1552 - final_regr: 0.0542\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.092\n","Classifier accuracy for bounding boxes from RPN: 0.93675\n","Loss RPN classifier: 0.12763926612665605\n","Loss RPN regression: 0.059206630741115075\n","Loss Detector classifier: 0.16445056783746986\n","Loss Detector regression: 0.052957966300426054\n","Total loss: 0.40425443100566705\n","Elapsed time: 452.79654812812805\n","Total loss decreased from 0.40928264865830527 to 0.40425443100566705, saving weights\n","Epoch 57/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.1101 - rpn_regr: 0.0689 - final_cls: 0.1966 - final_regr: 0.0539\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.068\n","Classifier accuracy for bounding boxes from RPN: 0.93\n","Loss RPN classifier: 0.09060110982551214\n","Loss RPN regression: 0.06626720178948017\n","Loss Detector classifier: 0.19670598741032883\n","Loss Detector regression: 0.05341056909481995\n","Total loss: 0.40698486812014106\n","Elapsed time: 458.34487795829773\n","Epoch 58/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.0916 - rpn_regr: 0.0632 - final_cls: 0.1782 - final_regr: 0.0492\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.033\n","Classifier accuracy for bounding boxes from RPN: 0.94075\n","Loss RPN classifier: 0.11786344926874269\n","Loss RPN regression: 0.05942729204022908\n","Loss Detector classifier: 0.15559963560559845\n","Loss Detector regression: 0.04891671722196043\n","Total loss: 0.3818070941365307\n","Elapsed time: 450.9768235683441\n","Total loss decreased from 0.40425443100566705 to 0.3818070941365307, saving weights\n","Epoch 59/70\n","1000/1000 [==============================] - 449s 449ms/step - rpn_cls: 0.1528 - rpn_regr: 0.0621 - final_cls: 0.2036 - final_regr: 0.0526\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.954\n","Classifier accuracy for bounding boxes from RPN: 0.9275\n","Loss RPN classifier: 0.12530690125772187\n","Loss RPN regression: 0.06474687817945232\n","Loss Detector classifier: 0.19935948785446816\n","Loss Detector regression: 0.053161454738583414\n","Total loss: 0.4425747220302258\n","Elapsed time: 456.8982849121094\n","Epoch 60/70\n","1000/1000 [==============================] - 453s 453ms/step - rpn_cls: 0.1465 - rpn_regr: 0.0577 - final_cls: 0.1533 - final_regr: 0.0486\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.055\n","Classifier accuracy for bounding boxes from RPN: 0.94275\n","Loss RPN classifier: 0.1332582899265542\n","Loss RPN regression: 0.0606235004122027\n","Loss Detector classifier: 0.15676501973421544\n","Loss Detector regression: 0.0504226216240786\n","Total loss: 0.401069431697051\n","Elapsed time: 453.3940279483795\n","Epoch 61/70\n","1000/1000 [==============================] - 447s 447ms/step - rpn_cls: 0.0875 - rpn_regr: 0.0557 - final_cls: 0.1848 - final_regr: 0.0521\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.058\n","Classifier accuracy for bounding boxes from RPN: 0.9305\n","Loss RPN classifier: 0.08994264310937664\n","Loss RPN regression: 0.06326620818937954\n","Loss Detector classifier: 0.18502040802639386\n","Loss Detector regression: 0.05380230133701116\n","Total loss: 0.39203156066216116\n","Elapsed time: 446.9005732536316\n","Epoch 62/70\n","1000/1000 [==============================] - 451s 451ms/step - rpn_cls: 0.1065 - rpn_regr: 0.0571 - final_cls: 0.1847 - final_regr: 0.0507\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.048\n","Classifier accuracy for bounding boxes from RPN: 0.9335\n","Loss RPN classifier: 0.08992302112102964\n","Loss RPN regression: 0.057091653671879614\n","Loss Detector classifier: 0.17821364126590197\n","Loss Detector regression: 0.04974740177183412\n","Total loss: 0.3749757178306453\n","Elapsed time: 450.55674743652344\n","Total loss decreased from 0.3818070941365307 to 0.3749757178306453, saving weights\n","Epoch 63/70\n","1000/1000 [==============================] - 450s 450ms/step - rpn_cls: 0.1384 - rpn_regr: 0.0582 - final_cls: 0.1391 - final_regr: 0.0490\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.996\n","Classifier accuracy for bounding boxes from RPN: 0.94075\n","Loss RPN classifier: 0.165761441488176\n","Loss RPN regression: 0.06165623767273428\n","Loss Detector classifier: 0.1584140615381475\n","Loss Detector regression: 0.050630807097652\n","Total loss: 0.4364625477967098\n","Elapsed time: 457.79764914512634\n","Epoch 64/70\n","1000/1000 [==============================] - 448s 448ms/step - rpn_cls: 0.1302 - rpn_regr: 0.0683 - final_cls: 0.1991 - final_regr: 0.0492\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 8.022\n","Classifier accuracy for bounding boxes from RPN: 0.92725\n","Loss RPN classifier: 0.13133383272043297\n","Loss RPN regression: 0.061044701728606016\n","Loss Detector classifier: 0.1902684411676528\n","Loss Detector regression: 0.0492770285026636\n","Total loss: 0.4319240041193554\n","Elapsed time: 448.3744511604309\n","Epoch 65/70\n","1000/1000 [==============================] - 453s 453ms/step - rpn_cls: 0.1272 - rpn_regr: 0.0573 - final_cls: 0.1642 - final_regr: 0.0485\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.99\n","Classifier accuracy for bounding boxes from RPN: 0.93325\n","Loss RPN classifier: 0.13381559748338334\n","Loss RPN regression: 0.056535437347887636\n","Loss Detector classifier: 0.1718291649702369\n","Loss Detector regression: 0.049598611090099436\n","Total loss: 0.4117788108916073\n","Elapsed time: 453.4258146286011\n","Epoch 66/70\n","1000/1000 [==============================] - 444s 444ms/step - rpn_cls: 0.1070 - rpn_regr: 0.0612 - final_cls: 0.1870 - final_regr: 0.0483\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.89\n","Classifier accuracy for bounding boxes from RPN: 0.93225\n","Loss RPN classifier: 0.1290082755460886\n","Loss RPN regression: 0.05872798230546868\n","Loss Detector classifier: 0.18801421706250404\n","Loss Detector regression: 0.048356786791468036\n","Total loss: 0.42410726170552937\n","Elapsed time: 444.10535430908203\n","Epoch 67/70\n","1000/1000 [==============================] - 450s 450ms/step - rpn_cls: 0.1468 - rpn_regr: 0.0565 - final_cls: 0.1568 - final_regr: 0.0511\n","Mean number of bounding boxes from RPN overlapping ground truth boxes: 7.953\n","Classifier accuracy for bounding boxes from RPN: 0.943\n","Loss RPN classifier: 0.19363005732720853\n","Loss RPN regression: 0.05963272618330666\n","Loss Detector classifier: 0.15503714343818864\n","Loss Detector regression: 0.04847773190028965\n","Total loss: 0.45677765884899346\n","Elapsed time: 449.9019420146942\n","Epoch 68/70\n"," 475/1000 [=============>................] - ETA: 3:56 - rpn_cls: 0.0514 - rpn_regr: 0.0482 - final_cls: 0.1760 - final_regr: 0.0553"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Kt-1Grs90oD3","colab":{}},"source":["plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(np.arange(0, r_epochs), record_df['mean_overlapping_bboxes'], 'r')\n","plt.title('mean_overlapping_bboxes')\n","plt.subplot(1,2,2)\n","plt.plot(np.arange(0, r_epochs), record_df['class_acc'], 'r')\n","plt.title('class_acc')\n","\n","plt.show()\n","\n","plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'r')\n","plt.title('loss_rpn_cls')\n","plt.subplot(1,2,2)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'r')\n","plt.title('loss_rpn_regr')\n","plt.show()\n","\n","\n","plt.figure(figsize=(15,5))\n","plt.subplot(1,2,1)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n","plt.title('loss_class_cls')\n","plt.subplot(1,2,2)\n","plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'r')\n","plt.title('loss_class_regr')\n","plt.show()\n","\n","plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n","plt.title('total_loss')\n","plt.show()\n","\n","# plt.figure(figsize=(15,5))\n","# plt.subplot(1,2,1)\n","# plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'r')\n","# plt.title('total_loss')\n","# plt.subplot(1,2,2)\n","# plt.plot(np.arange(0, r_epochs), record_df['elapsed_time'], 'r')\n","# plt.title('elapsed_time')\n","# plt.show()\n","\n","# plt.title('loss')\n","# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_cls'], 'b')\n","# plt.plot(np.arange(0, r_epochs), record_df['loss_rpn_regr'], 'g')\n","# plt.plot(np.arange(0, r_epochs), record_df['loss_class_cls'], 'r')\n","# plt.plot(np.arange(0, r_epochs), record_df['loss_class_regr'], 'c')\n","# # plt.plot(np.arange(0, r_epochs), record_df['curr_loss'], 'm')\n","# plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-fgI0ovv3zlr","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}